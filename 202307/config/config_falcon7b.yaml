model:
  pretrained_model_name_or_path: tiiuae/falcon-7b
  # device_map:
  #   '': 0
  device_map: auto
  # device_map:
  #   '': meta
  # load_in_8bit: true
  trust_remote_code: true

training:
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 1
  num_train_epochs: 3
  fp16: true
  optim: "adamw_torch"
  learning_rate: 1.0e-4
  logging_steps: 10
  evaluation_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 10
  save_steps: 100
  output_dir: /scratch/acf15478nt/models/tiiuae/falcon-7b
  save_total_limit: 3
#  deepspeed: ../finetune/ds_config_zero2.json

lora:
  r: 1
  lora_alpha: 1
  target_modules:
    - query_key_value
    - dense
    - dense_h_to_4h
    - dense_4h_to_h
  lora_dropout: 0.01
  bias: none
  task_type: CAUSAL_LM
  fan_in_fan_out: false

data:
  train: ../data/jsquad_train_v1.1.json
#   valid:
  valid_size: 0.2

prompt: |-
  タイトル: {title}
  
  文脈: {context}

  設問: {question}

  答え: {answers[text]}