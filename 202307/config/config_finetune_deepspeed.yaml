model:
  # device_map: cpu
  # device_map: auto
# model parallel training 可能なモデルの場合
  # device_map:
  #   '': 0
  trust_remote_code: true
  torch_dtype: torch.float16

training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 1
  num_train_epochs: 3
  fp16: false
  optim: "adamw_torch"
  learning_rate: 1.0e-3
  logging_steps: 10
  evaluation_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 100
  save_steps: 100
  save_total_limit: 3
#  deepspeed: ../finetune/ds_config_zero2.json
  deepspeed: ../finetune/ds_config_zero3.json

finetuning:
  trainables:
    # for GPT-2, cerebras/Cerebras-GPT-xx
    - ln_f
    # for GPT-NEOX, databricks/dolly-v2-xx, cyberagent/open-calm-xx
    - final_layer_norm
    - embed_out

data:
#   train_file: ../data/jsquad_train_v1.1.json
  train_file: ../data/jsquad_valid_v1.1.json
  valid_size: 0.01

outputs:
  dirname: /scratch/acf15478nt/models

prompt: |-
  タイトル: {title}
  
  文脈: {context}

  設問: {question}

  答え: {answers[text]}