INFO:root:model_name: /groups/4/gcb50389/pretrained/llama2-HF/Llama-2-7b-hf
INFO:root:load tokenizer
Using pad_token, but it is not set yet.
INFO:root:set pad_token to </s>
INFO:root:load model: {'pretrained_model_name_or_path': '/groups/4/gcb50389/pretrained/llama2-HF/Llama-2-7b-hf', 'device_map': 'auto', 'trust_remote_code': True}
INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/40877599.1.gpu/tmpy8rdleae
INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/40877599.1.gpu/tmpy8rdleae/_remote_module_non_scriptable.py
[2023-11-01 21:52:37,338] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [07:47<07:47, 467.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [09:05<00:00, 238.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [09:05<00:00, 272.93s/it]
INFO:root:processing R1 data.
Downloading and preparing dataset json/default to /scratch/acf15802az/.cache/huggingface/datasets/json/default-9daf52417ac5f3f8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 222.91it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        INFO:root:processing 20th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
INFO:root:processing 21th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
INFO:root:processing R2 data.
Dataset json downloaded and prepared to /scratch/acf15802az/.cache/huggingface/datasets/json/default-9daf52417ac5f3f8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.
Downloading and preparing dataset json/default to /scratch/acf15802az/.cache/huggingface/datasets/json/default-e81a17a045232274/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3104.59it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 212.04it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        INFO:root:processing 20th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
INFO:root:processing 21th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
INFO:root:processing R3 data.
Dataset json downloaded and prepared to /scratch/acf15802az/.cache/huggingface/datasets/json/default-e81a17a045232274/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.
Downloading and preparing dataset json/default to /scratch/acf15802az/.cache/huggingface/datasets/json/default-5930e0f5dc0720f3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 225.74it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        INFO:root:processing 20th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
INFO:root:processing 21th data.
Both `max_new_tokens` (=16) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Dataset json downloaded and prepared to /scratch/acf15802az/.cache/huggingface/datasets/json/default-5930e0f5dc0720f3/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.
